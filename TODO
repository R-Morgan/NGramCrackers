TODO


######
High
######

-- implement command line argument parsing and handling [Testing]

   -- Implement multiple modes
      
      -- Profile:
         
         This will provide a way to obtain general stats about a
         document. Some options will be:

         -w        word count
         -l        line count
         -t        type token ratio

      -- Extract:

         The will provide ways to obtain a profile with counts of all words
         and output it to a file. Ideally this will include functionality for
         n-gram extraction. Some options will be:

         -i        input file
         -o        output file
         -w        words
         -b        bigrams
         -t        trigrams
         -n        ngrams
   

-- implement lexeme frequency counter [Testing]

   -- The problem with this function is that it may count "".
      This will need to be corrected in the construction of
      lists
   
   -- countWord, getWordsFreqs, lexemeCountProfile are all
      related to this goal

-- implement n-gram frequency counter [Testing]

   -- I have done this for 1-grams with lexemeCountProfile. Once
      the n-grams are put into a list, the same sort of filtering
      mechanism to reduce the list size may work for n-grams


######
Med
######

-- implement functionality to parse multiple paragraphs. The Longman
   documents should be a good guide to determine what actually separates
   the paragraphs

-- Implement some sort of parser to count n-grams in files

-- Implement normalising function to count words like "The" and "the" to
   be parsed as the same word

######
Low
######

-- Make a variety of n-gram processing functions to output in
   several different formats (e.g., list of strings, tuple)

-- implement quickCheck tests

-- implement data types like Corpus, Document, Paragraph, Sentence, Word

-- Write more README.md 
   -- Complete V 0.0.1 Notes 
   -- Add Version 0.1.0 definition

