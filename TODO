TODO

######
High
######

- implement command line argument parsing and handling [Testing]

   - Implement multiple modes [Testing]
      
      - Profile:
         
         This will provide a way to obtain general stats about a
         document. Some options will be:

         -w        word count
         -l        line count
         -t        type token ratio
         -f        full profile

         -m        various means (words/sent sent/para)

      - Extract:

         The will provide ways to obtain a profile with counts of all words
         and output it to a file. Ideally this will include functionality for
         n-gram extraction. Some options will be:

         -i        input file
         -o        output file
         -w        words
         -b        bigrams
         -t        trigrams
         -n [Int]  ngrams

- implement quickCheck tests [testing]
   
   - test the text manipulation stuff -- i.e., the pure code

   - IO tests -- not sure how to do that

- Fix Bigram MI Profile function
- Write function to get MI of one bigram, given the bigram and a frequency
  map of the bigrams and the word counts

######
Med
######

- Implement the parsing of punctuation in Text literals, like ''' which can
  distinguish words (it's vs. its)

- Find out what are the edge cases in paragraph separation

  - Implement parsers to handle them. functionality to parse multiple
    paragraphs. The L. documents should be a good guide to determine what
    actually separates the paragraphs [testing]

- Implement normalising function to count words like "The" and "the" to
  be parsed as the same word

  - Likely possibly with `map T.lower`

######
Low
######

- Implement data types like Corpus, Document, Paragraph, Sentence, Word

- Metadata parsing capabilities [Testing]

- Metadata analysis facilities over file sets

########
On-Going
########

- Write more README.md 
- Version definition revisions
